{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qtxxs5VjS5dE"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Nji9uQZkTVoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Sem7/IMDB Dataset.csv')\n"
      ],
      "metadata": {
        "id": "LaAly9XbTsdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "SoBvjrvSTykL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_tags(text):\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'https?://\\S+', '', text)\n",
        "    # Remove non-alphanumeric characters and convert to lowercase\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
        "    return text"
      ],
      "metadata": {
        "id": "IeD682rLT3Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['review'] = data['review'].apply(remove_tags)"
      ],
      "metadata": {
        "id": "6fiJh84uT-9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['review'] = data['review'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n"
      ],
      "metadata": {
        "id": "kDTAa6t4UG4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "data['review'] = data['review'].apply(lemmatize_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7aZxSOuUJyP",
        "outputId": "a19daaa6-7eba-458a-fb7c-4d483ef24827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = data['review'].values\n",
        "labels = data['sentiment'].values\n",
        "encoder = LabelEncoder()\n",
        "encoded_labels = encoder.fit_transform(labels)\n",
        "train_sentences, test_sentences, train_labels, test_labels = train_test_split(reviews, encoded_labels, test_size=0.2, random_state=42, stratify=encoded_labels)\n"
      ],
      "metadata": {
        "id": "V-YGjKHtUdNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 3000  # Adjust based on your dataset\n",
        "embedding_dim = 100\n",
        "max_length = 200\n",
        "oov_tok = \"<OOV>\""
      ],
      "metadata": {
        "id": "7JETSNybUu4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')\n"
      ],
      "metadata": {
        "id": "VCL5MBK6U4sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dense(24, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "nhtbIJe7VEtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGkW8mQbVItq",
        "outputId": "ac15be8b-afda-43a1-adb4-33410b592a8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 200, 100)          300000    \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 200, 128)          84480     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 128)               98816     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense (Dense)               (None, 24)                3096      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 486417 (1.86 MB)\n",
            "Trainable params: 486417 (1.86 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "history = model.fit(train_padded, train_labels, epochs=num_epochs,  validation_split=0.1, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMD-bf9BVPCV",
        "outputId": "3b3e2a2f-b7a1-436b-c447-6883bede9faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1125/1125 [==============================] - 650s 569ms/step - loss: 0.4346 - accuracy: 0.8026 - val_loss: 0.3705 - val_accuracy: 0.8357\n",
            "Epoch 2/5\n",
            "1125/1125 [==============================] - 634s 564ms/step - loss: 0.3341 - accuracy: 0.8587 - val_loss: 0.3418 - val_accuracy: 0.8605\n",
            "Epoch 3/5\n",
            "1125/1125 [==============================] - 628s 559ms/step - loss: 0.2850 - accuracy: 0.8838 - val_loss: 0.3098 - val_accuracy: 0.8680\n",
            "Epoch 4/5\n",
            "1125/1125 [==============================] - 634s 563ms/step - loss: 0.2560 - accuracy: 0.8974 - val_loss: 0.3332 - val_accuracy: 0.8700\n",
            "Epoch 5/5\n",
            "1125/1125 [==============================] - 635s 564ms/step - loss: 0.2379 - accuracy: 0.9053 - val_loss: 0.3421 - val_accuracy: 0.8597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_padded, test_labels, verbose=1)\n",
        "print(\"Test accuracy:\", test_acc)\n",
        "\n",
        "# Predictions\n",
        "predictions = model.predict(test_padded)\n",
        "pred_labels = [1 if p >= 0.5 else 0 for p in predictions]\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(test_labels, pred_labels))\n",
        "print(\"Accuracy of prediction on test set:\", accuracy_score(test_labels, pred_labels))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_4g4f5qhnEP",
        "outputId": "774afc76-bde0-44f6-a8c1-6e1cb60f1a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 43s 137ms/step - loss: 0.3402 - accuracy: 0.8630\n",
            "Test accuracy: 0.8629999756813049\n",
            "313/313 [==============================] - 42s 136ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.80      0.85      5000\n",
            "           1       0.82      0.92      0.87      5000\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.87      0.86      0.86     10000\n",
            "weighted avg       0.87      0.86      0.86     10000\n",
            "\n",
            "Accuracy of prediction on test set: 0.863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict sentiment for custom sentences\n",
        "custom_sentences = [\"The concept of movie is good but I have watched better movies\",\n",
        "                    \"Lovely movie, the actors have acted excellently\",\n",
        "                    \"The movie plot is terrible but it also had bad acting\"]\n",
        "\n",
        "custom_sequences = tokenizer.texts_to_sequences(custom_sentences)\n",
        "custom_padded = pad_sequences(custom_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "custom_predictions = model.predict(custom_padded)\n",
        "custom_pred_labels = [1 if p >= 0.5 else 0 for p in custom_predictions]\n",
        "\n",
        "for i in range(len(custom_sentences)):\n",
        "    print(custom_sentences[i])\n",
        "    if custom_pred_labels[i] == 1:\n",
        "        print(\"Predicted sentiment: Positive\")\n",
        "    else:\n",
        "        print(\"Predicted sentiment: Negative\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDj6RtL9kIM_",
        "outputId": "ce31080a-b82c-40c2-8cd9-f6eb7a72d709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 113ms/step\n",
            "The concept of movie is good but I have watched better movies\n",
            "Predicted sentiment: Negative\n",
            "Lovely movie, the actors have acted excellently\n",
            "Predicted sentiment: Positive\n",
            "The movie plot is terrible but it also had bad acting\n",
            "Predicted sentiment: Negative\n"
          ]
        }
      ]
    }
  ]
}